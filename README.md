# SRE Spec Kit for Datadog

**A comprehensive maturity assessment and implementation framework for Datadog observability**

![Maturity Levels](https://img.shields.io/badge/Maturity%20Levels-6%20(0--5)-blue)
![Commands](https://img.shields.io/badge/Slash%20Commands-19-green)
![Notebook Templates](https://img.shields.io/badge/Notebook%20Templates-14-orange)

---

## ğŸš€ Quick Start

**New here?** Start with the [Quick Start Guide](./QUICKSTART.md) to run your first assessment in 5 minutes.

```bash
# Your first command - assess your current maturity
/assess
```

**Already familiar?** Jump to:
- [Command Reference](./COMMANDS.md) - All 19 slash commands
- [Level Definitions](./planning/level-definitions.md) - Detailed maturity criteria
- [Implementation Plan](./PLAN.md) - Project roadmap and status

---

## What is This?

The **SRE Spec Kit for Datadog** is a command-driven framework that helps SRE and platform engineering teams:

1. **Assess** current Datadog observability maturity (Levels 0-5)
2. **Identify** gaps in monitoring, tagging, cost optimization, and incident management
3. **Plan** step-by-step upgrades to advance SRE practices
4. **Document** investigations, postmortems, and reports using proven templates
5. **Track** progress over time with repeatable assessments

### Why Use This Kit?

- âœ… **Objective Assessment**: Uses real Datadog data via MCP (not surveys)
- âœ… **Industry Standards**: Based on SRE best practices and Datadog recommendations
- âœ… **Actionable Plans**: Get specific, prioritized steps to improve
- âœ… **Save Time**: Pre-built commands and templates (not starting from scratch)
- âœ… **Track Progress**: Repeatable assessments show maturity growth

---

## Maturity Levels Overview

| Level | Name | Focus | Timeline |
|-------|------|-------|----------|
| **Level 0** | Foundation | Basic observability setup | 1-2 months |
| **Level 1** | Standardization | Operational excellence | 2-3 months |
| **Level 2** | Optimization | Efficiency & scale | 3-4 months |
| **Level 3** | Intelligence | Proactive operations | 4-6 months |
| **Level 4** | Innovation | Advanced capabilities | 6-9 months |
| **Level 5** | Excellence | Industry leadership | 9-12 months |

**Total journey from Level 0 to Level 5**: Approximately 2-3 years

See [Level Definitions](./planning/level-definitions.md) for detailed requirements.

---

## ğŸ“‹ Command Categories

### Assessment Commands (6 commands)
Run maturity assessments and generate reports:
- `/assess` - Quick 10-minute maturity check
- `/assess-full` - Comprehensive 30-minute assessment
- `/assess-level0`, `/assess-level1` - Level-specific validation
- `/gap-analysis` - Identify gaps between current and target levels
- `/upgrade-plan` - Generate step-by-step upgrade roadmap

### Level 0 Foundation Commands (4 commands)
Establish baseline visibility:
- `/level0-infra` - Infrastructure discovery and inventory
- `/level0-tagging` - Tagging compliance audit
- `/level0-cost` - Cost baseline establishment
- `/level0-healthcheck` - Complete health check report

### Advanced Commands (2 commands)
Level 2+ capabilities:
- `/level2-tagging` - Advanced tagging strategy
- `/level3-cost` - Detailed cost optimization analysis

### Reporting & Documentation (4 commands)
Generate and share results:
- `/generate-report` - Executive summary generation
- `/save-to-notebook` - Save markdown to Datadog Notebook
- `/assess-to-notebook` - Assessment with Datadog export
- `/create-starter-notebooks` - Generate 14 template files

### Utilities (3 commands)
Helper commands:
- `/help` - List all available commands
- `/append-to-notebook` - Append to existing Datadog Notebook

**Total**: 19 slash commands

See [COMMANDS.md](./COMMANDS.md) for detailed command reference.

---

## ğŸ“Š 8 Assessment Dimensions

Every assessment evaluates your Datadog implementation across:

1. **Infrastructure Coverage** (25 points)
   - Agent deployment coverage
   - Cloud integration status
   - Service discovery

2. **Service Catalog** (10 points)
   - Service registration completeness
   - Ownership assignment
   - Metadata quality

3. **Tagging Compliance** (15 points)
   - UST tag coverage (env, service, version)
   - Tag consistency and format
   - Custom tag strategy

4. **Monitoring Quality** (15 points)
   - Monitor coverage by service tier
   - Alert quality and actionability
   - SLO tracking

5. **Log Management** (10 points)
   - Log collection coverage
   - Pipeline efficiency
   - Retention and archiving strategy

6. **Cost Optimization** (10 points)
   - Cost visibility by service/team
   - Resource efficiency
   - Optimization opportunities

7. **Incident Management** (10 points)
   - MTTR and MTTD metrics
   - Postmortem quality
   - Automation level

8. **Advanced Capabilities** (5 points)
   - APM, Synthetics, RUM usage
   - Automation and workflows
   - ML-powered features

**Maximum Score**: 100 points

See [Assessment Methodology](./planning/assessment-methodology.md) for scoring details.

---

## ğŸ“ Repository Structure

```
spec-kit-sre-datadog/
â”‚
â”œâ”€â”€ README.md                   â† You are here
â”œâ”€â”€ QUICKSTART.md              â† Start here for new users
â”œâ”€â”€ COMMANDS.md                 â† Complete command reference
â”œâ”€â”€ PLAN.md                     â† Implementation plan and status
â”œâ”€â”€ CLAUDE.md                   â† Claude Code integration guide
â”‚
â”œâ”€â”€ .claude/
â”‚   â””â”€â”€ commands/              â† 19 slash commands
â”‚       â”œâ”€â”€ assess.md
â”‚       â”œâ”€â”€ assess-full.md
â”‚       â”œâ”€â”€ level0-infra.md
â”‚       â””â”€â”€ ... (16 more)
â”‚
â”œâ”€â”€ planning/                   â† Framework documentation
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ level-definitions.md   â† Detailed maturity criteria
â”‚   â”œâ”€â”€ assessment-methodology.md
â”‚   â”œâ”€â”€ mcp-query-patterns.md
â”‚   â”œâ”€â”€ claude-md-strategy.md
â”‚   â””â”€â”€ notebook-templates-spec.md
â”‚
â”œâ”€â”€ notebooks/                  â† 14 ready-to-use templates
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ assessments/           â† 3 assessment templates
â”‚   â”œâ”€â”€ investigations/        â† 3 investigation templates
â”‚   â”œâ”€â”€ postmortems/           â† 2 postmortem templates
â”‚   â”œâ”€â”€ runbooks/              â† 3 runbook templates
â”‚   â””â”€â”€ reports/               â† 3 report templates
â”‚
â””â”€â”€ datadog-info/              â† Datadog account reference
    â””â”€â”€ (operational standards docs)
```

---

## ğŸ¯ Common Use Cases

### Use Case 1: New to Datadog SRE
**Goal**: Understand your starting point

```bash
# Day 1: Quick assessment
/assess

# Day 2: Baseline your infrastructure
/level0-infra
/level0-tagging
/level0-cost

# Day 3: Create improvement plan
/gap-analysis
/upgrade-plan
```

### Use Case 2: Quarterly Review
**Goal**: Track progress and report to leadership

```bash
# Run comprehensive assessment
/assess-full

# Generate executive report
/generate-report

# Save to Datadog for sharing
/save-to-notebook
```

### Use Case 3: Preparing for Next Level
**Goal**: Validate readiness to advance

```bash
# Check current level validation
/assess-level1

# Identify remaining gaps
/gap-analysis

# Create upgrade roadmap
/upgrade-plan
```

### Use Case 4: Incident Investigation
**Goal**: Document root cause and learnings

```bash
# Create investigation from template
/create-starter-notebooks

# Use notebooks/investigations/error-spike-investigation-template.md
# Customize for your incident
# Run embedded MCP queries
# Document findings

# Save to Datadog
/save-to-notebook
```

---

## ğŸ“š Documentation

### Getting Started
- **[QUICKSTART.md](./QUICKSTART.md)** - Start here! 5-minute quick start guide
- **[COMMANDS.md](./COMMANDS.md)** - Complete command reference with examples

### Planning & Methodology
- **[PLAN.md](./PLAN.md)** - Implementation plan and current status
- **[planning/level-definitions.md](./planning/level-definitions.md)** - Detailed maturity criteria
- **[planning/assessment-methodology.md](./planning/assessment-methodology.md)** - How assessments work
- **[planning/mcp-query-patterns.md](./planning/mcp-query-patterns.md)** - Common Datadog MCP queries

### Templates & Guides
- **[notebooks/README.md](./notebooks/README.md)** - Template library guide
- **[planning/notebook-templates-spec.md](./planning/notebook-templates-spec.md)** - Template specifications

### Integration
- **[CLAUDE.md](./CLAUDE.md)** - Claude Code integration strategy
- **[planning/claude-md-strategy.md](./planning/claude-md-strategy.md)** - MCP usage patterns

---

## ğŸ”§ Prerequisites

### Required
1. **Datadog Account** with API access
2. **Datadog MCP Server** installed and configured
   - See: https://docs.datadoghq.com/bits_ai/mcp_server/setup/
3. **Claude Code CLI** installed and running
4. **API/App Keys** with read permissions for:
   - Hosts, services, metrics
   - Logs, traces, events
   - Monitors, dashboards, notebooks

### Recommended Permissions
For full assessment capabilities, your API key should have:
- âœ… Read access to all Datadog resources
- âœ… Write access to notebooks (for `/save-to-notebook` commands)
- âœ… Cloud cost data access (for cost optimization)

---

## ğŸ“ Learning Path

### Week 1: Foundation
1. Read [QUICKSTART.md](./QUICKSTART.md)
2. Run `/assess` to understand your current level
3. Review [Level Definitions](./planning/level-definitions.md)
4. Run `/gap-analysis` to see what's missing

### Week 2-4: Level 0 Completion
1. Run `/level0-infra`, `/level0-tagging`, `/level0-cost`
2. Fix critical gaps (especially tagging)
3. Run `/assess-level0` to validate
4. Run `/level0-healthcheck` for complete report

### Month 2-3: Level 1 Advancement
1. Run `/upgrade-plan` for Level 1
2. Implement monitoring and SLOs
3. Set up log management
4. Run `/assess-level1` to validate

### Ongoing: Continuous Improvement
1. Run `/assess` weekly to track progress
2. Run `/assess-full` monthly for detailed review
3. Run `/generate-report` quarterly for leadership
4. Use notebook templates for investigations and postmortems

---

## ğŸ’¡ Best Practices

### Assessment Best Practices
1. **Start with Level 0** - Don't skip the foundation
2. **Run regularly** - Weekly quick checks, monthly deep dives
3. **Track progress** - Save assessment results over time
4. **Share results** - Use `/generate-report` for leadership updates

### Implementation Best Practices
1. **Follow the levels** - Each builds on the previous
2. **Fix tagging first** - It's the foundation for everything else
3. **Use templates** - Don't reinvent the wheel
4. **Document everything** - Use notebook templates for incidents

### Tool Usage
1. **Use slash commands** - Pre-built and tested
2. **Save to Datadog** - Use `/save-to-notebook` for collaboration
3. **Refer to planning docs** - When you need details
4. **Check COMMANDS.md** - For syntax and examples

---

## ğŸ†˜ Troubleshooting

### "Datadog MCP not found"
- Install Datadog MCP server: https://docs.datadoghq.com/bits_ai/mcp_server/setup/
- Verify configuration in Claude Code settings

### "Permission denied" errors
- Check API key permissions
- Ensure read access to all Datadog resources
- Verify API key is not expired

### Assessment shows unexpected low scores
- Check tagging compliance - it's often the culprit
- Verify data is flowing (agents reporting, logs ingesting)
- Run `/assess-full` for detailed breakdown

### Commands not found
- Commands are in `.claude/commands/` directory
- Use `/help` to list all available commands
- Check that you're using slash syntax: `/assess` not `assess`

---

## ğŸ¤ Contributing

This is an internal tool framework. To improve:

1. **Add new templates** - Create in `notebooks/` and document in README
2. **Enhance commands** - Update `.claude/commands/` files
3. **Improve docs** - Update planning documents
4. **Share learnings** - Document patterns in `planning/`

---

## ğŸ“ˆ Success Metrics

Track your SRE maturity journey:

- âœ… Initial assessment completed
- âœ… Current level identified and validated
- âœ… Gaps documented with priorities
- âœ… Upgrade plan created and approved
- âœ… Quarterly assessments scheduled
- âœ… Team aligned on SRE goals
- âœ… Executive reporting established
- âœ… Level advancement achieved

---

## ğŸ“ Getting Help

### Within This Repository
- **General usage**: [QUICKSTART.md](./QUICKSTART.md)
- **Command syntax**: [COMMANDS.md](./COMMANDS.md)
- **Assessment details**: [planning/assessment-methodology.md](./planning/assessment-methodology.md)
- **Level requirements**: [planning/level-definitions.md](./planning/level-definitions.md)

### External Resources
- **Datadog MCP**: https://docs.datadoghq.com/bits_ai/mcp_server/
- **Datadog Best Practices**: https://docs.datadoghq.com/
- **SRE Fundamentals**: https://sre.google/

---

## ğŸ“Š Project Status

**Current Implementation Status**: ~80% Complete

### âœ… Completed (Phases 1-7)
- Planning and methodology documentation
- Level definitions (Levels 0-5)
- 19 slash commands
- 14 notebook templates
- Assessment framework
- Quick start guide
- Command reference

### ğŸš§ In Progress (Phase 8)
- Maturity levels directory structure (P1)

### ğŸ“‹ Planned (Phases 9-11)
- Additional assessment commands (P2)
- Assessment automation tools (P2)
- Advanced level commands (P3)

See [PLAN.md](./PLAN.md) for detailed status and roadmap.

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸš€ Ready to Start?

**Your first command awaits:**

```bash
/assess
```

Or read the [Quick Start Guide](./QUICKSTART.md) for a guided introduction.

---

**Version**: 1.0
**Last Updated**: 2025-12-12
**Maintained By**: SRE Platform Team
